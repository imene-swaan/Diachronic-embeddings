

@inproceedings{window,
    title = "Dependency-Based Word Embeddings",
    author = "Levy, Omer  and
      Goldberg, Yoav",
    booktitle = "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = jun,
    year = "2014",
    address = "Baltimore, Maryland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P14-2050",
    doi = "10.3115/v1/P14-2050",
    pages = "302--308",
}


@InProceedings{dynamic,
  title = 	 {Dynamic Word Embeddings},
  author =       {Robert Bamler and Stephan Mandt},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {380--389},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/bamler17a/bamler17a.pdf},
  url = 	 {https://proceedings.mlr.press/v70/bamler17a.html},
  abstract = 	 {We present a probabilistic language model for time-stamped text data which tracks the semantic evolution of individual words over time. The model represents words and contexts by latent trajectories in an embedding space. At each moment in time, the embedding vectors are inferred from a probabilistic version of word2vec [Mikolov et al., 2013]. These embedding vectors are connected in time through a latent diffusion process. We describe two scalable variational inference algorithms–skip-gram smoothing and skip-gram filtering–that allow us to train the model jointly over all times; thus learning on all data while simultaneously allowing word and context vectors to drift. Experimental results on three different corpora demonstrate that our dynamic model infers word embedding trajectories that are more interpretable and lead to higher predictive likelihoods than competing methods that are based on static models trained separately on time slices.}
}



@inproceedings{armedconf,
    title = "Tracing armed conflicts with diachronic word embedding models",
    author = "Kutuzov, Andrey  and
      Velldal, Erik  and
      {\O}vrelid, Lilja",
    booktitle = "Proceedings of the Events and Stories in the News Workshop",
    month = aug,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W17-2705",
    doi = "10.18653/v1/W17-2705",
    pages = "31--36",
    abstract = "Recent studies have shown that word embedding models can be used to trace time-related (diachronic) semantic shifts in particular words. In this paper, we evaluate some of these approaches on the new task of predicting the dynamics of global armed conflicts on a year-to-year basis, using a dataset from the conflict research field as the gold standard and the Gigaword news corpus as the training data. The results show that much work still remains in extracting {`}cultural{'} semantic shifts from diachronic word embedding models. At the same time, we present a new task complete with an evaluation set and introduce the {`}anchor words{'} method which outperforms previous approaches on this set.",
}

@inproceedings{kanjirangat-etal-2020-sst,
    title = "{SST}-{BERT} at {S}em{E}val-2020 Task 1: Semantic Shift Tracing by Clustering in {BERT}-based Embedding Spaces",
    author = "Kanjirangat, Vani  and
      Mitrovic, Sandra  and
      Antonucci, Alessandro  and
      Rinaldi, Fabio",
    booktitle = "Proceedings of the Fourteenth Workshop on Semantic Evaluation",
    month = dec,
    year = "2020",
    address = "Barcelona (online)",
    publisher = "International Committee for Computational Linguistics",
    url = "https://aclanthology.org/2020.semeval-1.26",
    doi = "10.18653/v1/2020.semeval-1.26",
    pages = "214--221",
    abstract = "Lexical semantic change detection (also known as semantic shift tracing) is a task of identifying words that have changed their meaning over time. Unsupervised semantic shift tracing, focal point of SemEval2020, is particularly challenging. Given the unsupervised setup, in this work, we propose to identify clusters among different occurrences of each target word, considering these as representatives of different word meanings. As such, disagreements in obtained clusters naturally allow to quantify the level of semantic shift per each target word in four target languages. To leverage this idea, clustering is performed on contextualized (BERT-based) embeddings of word occurrences. The obtained results show that our approach performs well both measured separately (per language) and overall, where we surpass all provided SemEval baselines.",
}


@inproceedings{kim-etal-2014-temporal,
    title = "Temporal Analysis of Language through Neural Language Models",
    author = "Kim, Yoon  and
      Chiu, Yi-I  and
      Hanaki, Kentaro  and
      Hegde, Darshan  and
      Petrov, Slav",
    booktitle = "Proceedings of the {ACL} 2014 Workshop on Language Technologies and Computational Social Science",
    month = jun,
    year = "2014",
    address = "Baltimore, MD, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W14-2517",
    doi = "10.3115/v1/W14-2517",
    pages = "61--65",
}

@inproceedings{giulianelli-etal-2020-analysing,
    title = "Analysing Lexical Semantic Change with Contextualised Word Representations",
    author = "Giulianelli, Mario  and
      Del Tredici, Marco  and
      Fern{\'a}ndez, Raquel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.365",
    doi = "10.18653/v1/2020.acl-main.365",
    pages = "3960--3973",
    abstract = "This paper presents the first unsupervised approach to lexical semantic change that makes use of contextualised word representations. We propose a novel method that exploits the BERT neural language model to obtain representations of word usages, clusters these representations into usage types, and measures change along time with three proposed metrics. We create a new evaluation dataset and show that the model representations and the detected semantic shifts are positively correlated with human judgements. Our extensive qualitative analysis demonstrates that our method captures a variety of synchronic and diachronic linguistic phenomena. We expect our work to inspire further research in this direction.",
}

@inproceedings{periti-etal-2022-done,
    title = "What is Done is Done: an Incremental Approach to Semantic Shift Detection",
    author = "Periti, Francesco  and
      Ferrara, Alfio  and
      Montanelli, Stefano  and
      Ruskov, Martin",
    booktitle = "Proceedings of the 3rd Workshop on Computational Approaches to Historical Language Change",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.lchange-1.4",
    doi = "10.18653/v1/2022.lchange-1.4",
    pages = "33--43",
    abstract = "Contextual word embedding techniques for semantic shift detection are receiving more and more attention. In this paper, we present What is Done is Done (WiDiD), an incremental approach to semantic shift detection based on incremental clustering techniques and contextual embedding methods to capture the changes over the meanings of a target word along a diachronic corpus. In WiDiD, the word contexts observed in the past are consolidated as a set of clusters that constitute the {``}memory{''} of the word meanings observed so far. Such a memory is exploited as a basis for subsequent word observations, so that the meanings observed in the present are stratified over the past ones.",
}

@misc{montanelli2023survey,
      title={A Survey on Contextualised Semantic Shift Detection}, 
      author={Stefano Montanelli and Francesco Periti},
      year={2023},
      eprint={2304.01666},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@inbook{Rodina,
author = {Rodina, Julia and Trofimova, Yuliya and Kutuzov, Andrei and Artemova, Ekaterina},
year = {2021},
month = {04},
pages = {175-186},
title = {ELMo and BERT in Semantic Change Detection for Russian},
isbn = {978-3-030-72609-6},
doi = {10.1007/978-3-030-72610-2_13}
}

@InProceedings{pmlr-v70-bamler17a,
  title = 	 {Dynamic Word Embeddings},
  author =       {Robert Bamler and Stephan Mandt},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {380--389},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/bamler17a/bamler17a.pdf},
  url = 	 {https://proceedings.mlr.press/v70/bamler17a.html},
  abstract = 	 {We present a probabilistic language model for time-stamped text data which tracks the semantic evolution of individual words over time. The model represents words and contexts by latent trajectories in an embedding space. At each moment in time, the embedding vectors are inferred from a probabilistic version of word2vec [Mikolov et al., 2013]. These embedding vectors are connected in time through a latent diffusion process. We describe two scalable variational inference algorithms–skip-gram smoothing and skip-gram filtering–that allow us to train the model jointly over all times; thus learning on all data while simultaneously allowing word and context vectors to drift. Experimental results on three different corpora demonstrate that our dynamic model infers word embedding trajectories that are more interpretable and lead to higher predictive likelihoods than competing methods that are based on static models trained separately on time slices.}
}


@inproceedings{shoemark-etal-2019-room,
    title = "Room to {G}lo: A Systematic Comparison of Semantic Change Detection Approaches with Word Embeddings",
    author = "Shoemark, Philippa  and
      Liza, Farhana Ferdousi  and
      Nguyen, Dong  and
      Hale, Scott  and
      McGillivray, Barbara",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1007",
    doi = "10.18653/v1/D19-1007",
    pages = "66--76",
    abstract = "Word embeddings are increasingly used for the automatic detection of semantic change; yet, a robust evaluation and systematic comparison of the choices involved has been lacking. We propose a new evaluation framework for semantic change detection and find that (i) using the whole time series is preferable over only comparing between the first and last time points; (ii) independently trained and aligned embeddings perform better than continuously trained embeddings for long time periods; and (iii) that the reference point for comparison matters. We also present an analysis of the changes detected on a large Twitter dataset spanning 5.5 years.",
}


@inproceedings{hu-etal-2019-diachronic,
    title = "Diachronic Sense Modeling with Deep Contextualized Word Embeddings: An Ecological View",
    author = "Hu, Renfen  and
      Li, Shen  and
      Liang, Shichen",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1379",
    doi = "10.18653/v1/P19-1379",
    pages = "3899--3908",
    abstract = "Diachronic word embeddings have been widely used in detecting temporal changes. However, existing methods face the meaning conflation deficiency by representing a word as a single vector at each time period. To address this issue, this paper proposes a sense representation and tracking framework based on deep contextualized embeddings, aiming at answering not only what and when, but also how the word meaning changes. The experiments show that our framework is effective in representing fine-grained word senses, and it brings a significant improvement in word change detection task. Furthermore, we model the word change from an ecological viewpoint, and sketch two interesting sense behaviors in the process of language evolution, i.e. sense competition and sense cooperation.",
}

@inproceedings{hamilton-etal-2016-diachronic,
    title = "Diachronic Word Embeddings Reveal Statistical Laws of Semantic Change",
    author = "Hamilton, William L.  and
      Leskovec, Jure  and
      Jurafsky, Dan",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P16-1141",
    doi = "10.18653/v1/P16-1141",
    pages = "1489--1501",
}



@inproceedings{survey,
    title = "Diachronic word embeddings and semantic shifts: a survey",
    author = "Kutuzov, Andrey  and
      {\O}vrelid, Lilja  and
      Szymanski, Terrence  and
      Velldal, Erik",
    booktitle = "Proceedings of the 27th International Conference on Computational Linguistics",
    month = aug,
    year = "2018",
    address = "Santa Fe, New Mexico, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/C18-1117",
    pages = "1384--1397",
    abstract = "Recent years have witnessed a surge of publications aimed at tracing temporal changes in lexical semantics using distributional methods, particularly prediction-based word embedding models. However, this vein of research lacks the cohesion, common terminology and shared practices of more established areas of natural language processing. In this paper, we survey the current state of academic research related to diachronic word embeddings and semantic shifts detection. We start with discussing the notion of semantic shifts, and then continue with an overview of the existing methods for tracing such time-related shifts with word embedding models. We propose several axes along which these methods can be compared, and outline the main challenges before this emerging subfield of NLP, as well as prospects and possible applications.",
}

@inproceedings{dubossarsky-etal-2017-outta,
    title = "Outta Control: Laws of Semantic Change and Inherent Biases in Word Representation Models",
    author = "Dubossarsky, Haim  and
      Weinshall, Daphna  and
      Grossman, Eitan",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D17-1118",
    doi = "10.18653/v1/D17-1118",
    pages = "1136--1145",
    abstract = "This article evaluates three proposed laws of semantic change. Our claim is that in order to validate a putative law of semantic change, the effect should be observed in the genuine condition but absent or reduced in a suitably matched control condition, in which no change can possibly have taken place. Our analysis shows that the effects reported in recent literature must be substantially revised: (i) the proposed negative correlation between meaning change and word frequency is shown to be largely an artefact of the models of word representation used; (ii) the proposed negative correlation between meaning change and prototypicality is shown to be much weaker than what has been claimed in prior art; and (iii) the proposed positive correlation between meaning change and polysemy is largely an artefact of word frequency. These empirical observations are corroborated by analytical proofs that show that count representations introduce an inherent dependence on word frequency, and thus word frequency cannot be evaluated as an independent factor with these representations.",
}


@inproceedings{schlechtweg-etal-2020-semeval,
    title = "{S}em{E}val-2020 Task 1: Unsupervised Lexical Semantic Change Detection",
    author = "Schlechtweg, Dominik  and
      McGillivray, Barbara  and
      Hengchen, Simon  and
      Dubossarsky, Haim  and
      Tahmasebi, Nina",
    booktitle = "Proceedings of the Fourteenth Workshop on Semantic Evaluation",
    month = dec,
    year = "2020",
    address = "Barcelona (online)",
    publisher = "International Committee for Computational Linguistics",
    url = "https://aclanthology.org/2020.semeval-1.1",
    doi = "10.18653/v1/2020.semeval-1.1",
    pages = "1--23",
    abstract = "Lexical Semantic Change detection, i.e., the task of identifying words that change meaning over time, is a very active research area, with applications in NLP, lexicography, and linguistics. Evaluation is currently the most pressing problem in Lexical Semantic Change detection, as no gold standards are available to the community, which hinders progress. We present the results of the first shared task that addresses this gap by providing researchers with an evaluation framework and manually annotated, high-quality datasets for English, German, Latin, and Swedish. 33 teams submitted 186 systems, which were evaluated on two subtasks.",
}

@inproceedings{cook-etal-2014-novel,
    title = "Novel Word-sense Identification",
    author = "Cook, Paul  and
      Lau, Jey Han  and
      McCarthy, Diana  and
      Baldwin, Timothy",
    booktitle = "Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",
    month = aug,
    year = "2014",
    address = "Dublin, Ireland",
    publisher = "Dublin City University and Association for Computational Linguistics",
    url = "https://aclanthology.org/C14-1154",
    pages = "1624--1635",
}

@article{article,
author = {Kilgarriff, Adam},
year = {1999},
month = {04},
pages = {},
title = {"I don't believe in word senses"},
volume = {31},
journal = {Computers and the Humanities}
}
